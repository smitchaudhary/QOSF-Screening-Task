{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QOSF Mentorship Program - Screening Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitted By : Smit Chaudhary\n",
    "\n",
    "### Task Chosen : Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a circuit that returns state $|01\\rangle$ and state $|10\\rangle$ with equal probability (50% each).\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- The circuit should consist only of CNOTs, RXs and RYs.\n",
    "- Start from all parameters in parametric gates being equal to 0 or randomly chosen.\n",
    "- You should find the right set of parameters using gradient descent (you can use more advanced optimization methods if you like).\n",
    "- Simulations must be done with sampling (i.e. a limited number of measurements per iteration) and noise.\n",
    "\n",
    "Compare the results for different numbers of measurements: 1, 10, 100, 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse the Problem\n",
    "\n",
    "Firstly, we notice that the task of getting one of the bell state is a task that is routinely performed for many algorithms and protocols such as *Super-dense Coding*, *Quantum Teleportation* etc. Thus, it is a fairly well known task.\n",
    "\n",
    "Consider the following circuit:\n",
    "\n",
    "<img src = '1.png'>\n",
    "\n",
    "*Screenshot taken from [Quantum-Inspie](https://www.quantum-inspire.com/)*\n",
    "\n",
    "This simple circuit with 2 gates would give us a bell state. Though notably, one would not get an equal superposition of $|01\\rangle$ and $|10\\rangle$ as we wanted but an equal superposition of $|00\\rangle$ and $|11\\rangle$.\n",
    "\n",
    "Though we can flip any of the two qubit either at the beginning or at the end to get an equal superposition of $|01\\rangle$ and $|10\\rangle$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, having established the fact that it is a fairly simply procedure, we notice that in our task, we are not allowed to use the hadamard gate and only allowed to use the parameteric $R_x$, $R_y$ gates and the CNOT gate.\n",
    "\n",
    "Thus, we will have to decompose the X gate and the Hadamard gate in terms of these gates to be able to solve our problem.\n",
    "\n",
    "Firstly, X gate is same as rotating the qubits around Y axis by $\\pi$.\n",
    "\n",
    "Then, we see that the Hadamard gate is a combination of rotation about X axis by $\\pi/2$ and rotation about Y by $\\pi/2$.\n",
    "\n",
    "For the CNOT gate, we directly apply the CNOT gate since we are allowed to use it.\n",
    "\n",
    "But, in the problem, we are not allowed to directly use $\\pi$ or $\\pi2$. Thus, we will initialise the parametric gates $R_x$ and $R_y$ with parameters (which are the angles of rotation) being equal to 0. We will construct a cost function and try to minimize it using gradient descent to find the optimal values of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gradient Descent\n",
    "It is an iterative optimization algorithm to find local minima. We need to be careful with the parameters (of gradient descent, and not the function) we choose while applying gradient descent.\n",
    "\n",
    "Here, we take a `function_to_be_minimized` and find the values of the parameters for which it is minimum.\n",
    "\n",
    "We need to choose certain parameters of the gradient descent.\n",
    "\n",
    "Learning rate = 0.8  \n",
    "Step size = 0.005  \n",
    "Maximum iterations of gradient descent = 1000\n",
    "\n",
    "Note that we have maximum iterations of gradient descent set at 1000 since we don't want our iterative process to continue indefinitely.\n",
    "\n",
    "We need to ensure Learning rate and Step Size are not too big or we could miss the minima altogether.\n",
    "\n",
    "To start, we import some useful libraries and define our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from qiskit import(Aer, QuantumCircuit, execute)\n",
    "import qiskit.providers.aer.noise as noise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "backend = Aer.get_backend('statevector_simulator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_measurements = [1, 10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.8\n",
    "step_size = 0.005\n",
    "max_gd_iter = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to apply gradient descent and find the optimal values of parameters but to help facilitate that, let us define a couple of functions first. These are the sub-tasks that we need to perform repeatedly so let us define these functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(circuit, no_of_measurements):\n",
    "    \n",
    "    circuit.measure_all()\n",
    "    result = execute(circuit, simulator, shots=no_of_measurements, noise_model=noise.NoiseModel()).result()\n",
    "    counts  = result.get_counts(circuit)\n",
    "    return counts\n",
    "\n",
    "def probability(count, no_of_measurements):\n",
    "    \n",
    "    probability_0 = 0\n",
    "    probability_1 = 0\n",
    "    \n",
    "    if '0' in count.keys():\n",
    "        probability_0 = int(count['0'])/no_of_measurements\n",
    "    if '1' in count.keys():\n",
    "        probability_1 = int(count['1'])/no_of_measurements  \n",
    "        \n",
    "    return  probability_0, probability_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are two fairly simple functions whose names are self explantory. The function `get_counts` measures and gives us the counts for each measurement state. Similarly, the function`probability` gives us the probability based on those counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, but more importantly, we now break down the gradient descent process in smaller functions. The description of functions follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_derivative(theta_index, function_to_be_minimised, theta, function_value, no_of_measurements):\n",
    "\n",
    "    new_theta = theta.copy()\n",
    "    \n",
    "    new_theta[theta_index] = theta[theta_index] + step_size\n",
    "    new_function_value = function_to_be_minimised(new_theta, no_of_measurements)\n",
    "    \n",
    "    derivative = (new_function_value - function_value)/step_size\n",
    "    return derivative\n",
    "\n",
    "def update_theta(theta_index, theta, gradient):\n",
    "    \n",
    "    theta[theta_index] -= learning_rate*gradient[theta_index]\n",
    "    theta[theta_index] =  theta[theta_index] % (2*np.pi)\n",
    "    \n",
    "    return theta[theta_index]\n",
    "\n",
    "def gradient_descent(initial_theta, function_to_be_minimised, no_of_measurements): \n",
    "    \n",
    "    theta = np.array(initial_theta).copy()\n",
    "    dimensions_of_theta = len(initial_theta)\n",
    "    \n",
    "    min_theta = np.array(theta).copy()\n",
    "    function_value = function_to_be_minimised(theta, no_of_measurements)\n",
    "    min_function_value = function_value \n",
    "    \n",
    "    for iteration in range(max_gd_iter): \n",
    "       \n",
    "       gradient = []\n",
    "       for theta_index in range(dimensions_of_theta):\n",
    "          deriv = calculate_derivative(theta_index, function_to_be_minimised, theta, function_value, no_of_measurements)\n",
    "          gradient.append(deriv)\n",
    "\n",
    "       for theta_index in range(dimensions_of_theta): \n",
    "          theta[theta_index] = update_theta(theta_index, theta, gradient)\n",
    "    \n",
    "       function_value = function_to_be_minimised(theta, no_of_measurements)\n",
    "       \n",
    "       if (function_value == 0): \n",
    "           min_function_value = function_value\n",
    "           min_theta = np.array(theta).copy()\n",
    "        \n",
    "       if (min_function_value > function_value):\n",
    "           min_function_value = function_value\n",
    "           min_theta = np.array(theta).copy()\n",
    "         \n",
    "    print(\"Minimum value of the function: \", function_value)\n",
    "    print(\"Value of theta for minnima of function: \", min_theta)\n",
    "    return min_function_value, min_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calculate_derivative` is a function that calculates the derivative of the function with respect to whatever parameter is given. Note that we call it derivative as of now and not the gradient since when the function's support spans more than 1 dimensions, gradient would be array of these derivatives.\n",
    "\n",
    "`update_theta` function updates the value of `theta` (which could be an array) based on the value of the gradient. We want each $\\theta \\in [0,2\\pi]$. So we take modulo $2\\pi$.\n",
    "\n",
    "Finally, `gradient_descent` performs the entire gradient descent algorithm and returns a tuple which has the minimum value of the function that is to be minimised and also the value of the input parameters at which this minima is achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding theta for X Gate\n",
    "\n",
    "Now, since we have all our tools in aresenal, let us find the value of theta such that we get $X$ gate from the parametric gate.\n",
    "\n",
    "Note that if we had an X gate and applied on state $|0\\rangle$ we would get $|1\\rangle$ and upon measurement, the probability of getting state $|0\\rangle$ is 0 and probability of getting state $|1\\rangle$ is 1.\n",
    "\n",
    "Thus, we can define the error function, which is to be minimised as\n",
    "$$f = (prob(0) - 0)^2 + (prob(1) - 1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 1 measurement(s):\n",
      "Minimum value of the function:  0.0\n",
      "Value of theta for minnima of function:  [3.16465808]\n",
      "\n",
      "For 10 measurement(s):\n",
      "Minimum value of the function:  0.0\n",
      "Value of theta for minnima of function:  [3.11865478]\n",
      "\n",
      "For 100 measurement(s):\n",
      "Minimum value of the function:  0.0\n",
      "Value of theta for minnima of function:  [3.1376197]\n",
      "\n",
      "For 1000 measurement(s):\n",
      "Minimum value of the function:  0.0\n",
      "Value of theta for minnima of function:  [3.15345808]\n"
     ]
    }
   ],
   "source": [
    "def function_for_X(theta, no_of_measurements):\n",
    "    circuit = QuantumCircuit(1)\n",
    "    \n",
    "    # X gate on qubit 1\n",
    "    circuit.ry(theta[0], 0)\n",
    "    \n",
    "    count = get_counts(circuit, no_of_measurements)\n",
    "    probability_0, probability_1 = probability(count, no_of_measurements)\n",
    " \n",
    "    function_val = ((float(probability_0) - 0)**2 + (float(probability_1) - 1)**2)\n",
    "    return function_val\n",
    "\n",
    "initial_theta = [random.uniform(0, 2*np.pi)]\n",
    "\n",
    "X_results = {}\n",
    "\n",
    "for n in number_of_measurements:\n",
    "    print()\n",
    "    print(\"For\", n, \"measurement(s):\")\n",
    "    \n",
    "    min_function_value, min_theta = gradient_descent(initial_theta, function_for_X, n)\n",
    "    X_results[n] = [min_function_value, min_theta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding theta for H Gate\n",
    "\n",
    "Now, since we have all our tools in aresenal, let us find the value of theta such that we get $H$ gate from the parametric gates.\n",
    "\n",
    "Note that if we had an H gate and applied on state $|0\\rangle$ we would get $|+\\rangle$ and upon measurement, the probability of getting state $|0\\rangle$ is 0.5 and probability of getting state $|1\\rangle$ is 0.5\n",
    "\n",
    "Thus, we can define the error function, which is to be minimised as\n",
    "$$f = (prob(0) - 0.5)^2 + (prob(1) - 0.5)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For 1 measurement(s):\n",
      "Minimum value of the function:  0.5\n",
      "Value of theta for minnima of function:  [4.37827078 4.54520318]\n",
      "\n",
      "For 10 measurement(s):\n",
      "Minimum value of the function:  0.0\n",
      "Value of theta for minnima of function:  [4.93753614 4.03194111]\n",
      "\n",
      "For 100 measurement(s):\n",
      "Minimum value of the function:  0.5\n",
      "Value of theta for minnima of function:  [4.76071486 3.40283256]\n",
      "\n",
      "For 1000 measurement(s):\n",
      "Minimum value of the function:  0.014791999999999996\n",
      "Value of theta for minnima of function:  [4.78500547 1.43736318]\n"
     ]
    }
   ],
   "source": [
    "def function_for_H(theta, no_of_measurements):\n",
    "    circuit = QuantumCircuit(1)\n",
    "    \n",
    "    circuit.ry(theta[0],0)\n",
    "    circuit.rx(theta[1],0)\n",
    "\n",
    "    count = get_counts(circuit, no_of_measurements)\n",
    "    probability_0, probability_1 = probability(count, no_of_measurements)\n",
    "    \n",
    "    function_val = ((float(probability_0) - 0.5)**2 + (float(probability_1) - 0.5)**2)\n",
    "    return function_val\n",
    "\n",
    "initial_theta = [random.uniform(0,2*np.pi), random.uniform(0,2*np.pi)]\n",
    "\n",
    "H_results = {}\n",
    "\n",
    "for n in number_of_measurements:\n",
    "    print()\n",
    "    print(\"For\", n, \"measurement(s):\")\n",
    "    \n",
    "    min_function_value, min_theta = gradient_descent(initial_theta, function_for_H, n)\n",
    "    H_results[n] = [min_function_value, min_theta]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the Results\n",
    "\n",
    "This would be a good time to look at our results and comment on some interesting artefacts. Which are interesting in themselves but also help us understand the intricacies of the process and help us solve the bonus part of the question.\n",
    "\n",
    "### The curious case of H gate\n",
    "\n",
    "If we go by the names of variables and functions, it seems like using gradient descent we have found the parameters which would help us administer a Hadamard Gate but that is not true. The function that we are minimising dictates that we get a final state such that the probability of getting $|0\\rangle$ and $|1\\rangle$ are 0.5 each. This could happen in many different ways and we need not apply exactly the Hadamard Gate to get these values. Note that we would want both the angles to be $\\pi/2$ to get Hadamard. But even if we applied a gate that took $|0\\rangle$ to $|-\\rangle$ instead of $|+\\rangle$ we would still get equal probability and the error function woudl be minimum there.\n",
    "\n",
    "And since we randomly initialise our parameters, we are not sure where exactly the function would converge to.\n",
    "\n",
    "### But does it really work?\n",
    "\n",
    "Let us apply the parametric circuit on a system and check the results. Note, that the third part is applying a CNOT gate which we are allowed to and we don't need to optimize anything for it.\n",
    "\n",
    "To do this, let us define a function that gives us probabilities, similar to the one we defined earlier but this time for 2 qubits instead of just 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_2_qubits(count, no_of_measurements):\n",
    "    \n",
    "    probability_00 = 0\n",
    "    probability_01 = 0\n",
    "    probability_10 = 0\n",
    "    probability_11 = 0\n",
    "    \n",
    "    if '00' in count.keys():\n",
    "        probability_00 = int(count['00'])/no_of_measurements\n",
    "    if '01' in count.keys():\n",
    "        probability_01 = int(count['01'])/no_of_measurements\n",
    "    if '10' in count.keys():\n",
    "        probability_10 = int(count['10'])/no_of_measurements\n",
    "    if '11' in count.keys():\n",
    "        probability_11 = int(count['11'])/no_of_measurements\n",
    "        \n",
    "    return  probability_00, probability_01, probability_10, probability_11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check the results using a function that first applies all the gates using the parameters we arrived at and then returns the counts for each state along with the function value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_results(X_results, H_results):\n",
    "    \n",
    "    counts = []\n",
    "    func_values = []\n",
    "    \n",
    "    for n in number_of_measurements:    \n",
    "        circuit = QuantumCircuit(2)\n",
    "\n",
    "        circuit.ry(X_results[n][1][0],1)\n",
    "\n",
    "        circuit.ry(H_results[n][1][0],0)\n",
    "        circuit.rx(H_results[n][1][1],0)\n",
    "\n",
    "        circuit.cx(0,1)\n",
    "        \n",
    "        count = get_results(circuit, n)\n",
    "        counts.append(count)\n",
    "        \n",
    "        probability_00, probability_01, probability_10, probability_11 = probability_2_qubits(count, n)\n",
    "        \n",
    "        function_val = ((float(probability_00) - 0)**2 + (float(probability_01) - 0.5)**2 + (float(probability_10) - 0.5)**2 + (float(probability_11) - 0)**2)\n",
    "        func_values.append(function_val)         \n",
    "    return counts, func_values\n",
    "        \n",
    "counts, function_values = check_results(X_results, H_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Nothing happened. Not yet. We can now check these results and compare them to what we expect for an ideal X and H gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for  1 measurements, we have:\n",
      "probability of getting 00 is  0\n",
      "probability of getting 01 is  1.0\n",
      "probability of getting 10 is  0\n",
      "probability of getting 11 is  0\n",
      "\n",
      "for  10 measurements, we have:\n",
      "probability of getting 00 is  0\n",
      "probability of getting 01 is  0.4\n",
      "probability of getting 10 is  0.6\n",
      "probability of getting 11 is  0\n",
      "\n",
      "for  100 measurements, we have:\n",
      "probability of getting 00 is  0\n",
      "probability of getting 01 is  0.53\n",
      "probability of getting 10 is  0.47\n",
      "probability of getting 11 is  0\n",
      "\n",
      "for  1000 measurements, we have:\n",
      "probability of getting 00 is  0\n",
      "probability of getting 01 is  0.482\n",
      "probability of getting 10 is  0.518\n",
      "probability of getting 11 is  0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    probability_00 = 0\n",
    "    probability_01 = 0\n",
    "    probability_10 = 0\n",
    "    probability_11 = 0\n",
    "    \n",
    "    print(\"for \", number_of_measurements[i], \"measurements, we have:\")\n",
    "    if '00' in counts[i].keys():\n",
    "        probability_00 = float(counts[i]['00'])/number_of_measurements[i]\n",
    "    print(\"probability of getting 00 is \", probability_00)\n",
    "    if '01' in counts[i].keys():\n",
    "        probability_01 = float(counts[i]['01'])/number_of_measurements[i]\n",
    "    print(\"probability of getting 01 is \", probability_01)\n",
    "    if '10' in counts[i].keys():\n",
    "        probability_10 = float(counts[i]['10'])/number_of_measurements[i]\n",
    "    print(\"probability of getting 10 is \", probability_10)\n",
    "    if '11' in counts[i].keys():\n",
    "        probability_11 = float(counts[i]['11'])/number_of_measurements[i]\n",
    "    print(\"probability of getting 11 is \", probability_11)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! This looks neat but why is the probability not close to 0.5 for 1 measurement? It is simply becasue if we have one measurement, we get either 01 or 10. And then when we calculate probability based on our observation, we will get probability 1 for either of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also ties in to how as the number of measurements increase, the error reduces. We find the maximum error for 1 measurement and the least for 1000 measurements. For n measurements where n is large enough, we would find the probability to be 0.5 for both the states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Question\n",
    "\n",
    "You thought we were done? Not yet. But almost. We are going to take a shortcut here. We can have Qiskit provide us the state our qubit(s) are in and then can simply see if we have the right state to check if we are getting $\\frac{1}{\\sqrt{2}}\\left(|01\\rangle + |10\\rangle\\right)$ or some other state which gives us these two states with probability 0.5\n",
    "\n",
    "We are going to ensure that this time we aactually apply the Hadamard gate and not anything else. A hadamard gate would take $|0\\rangle$ to $\\frac{1}{\\sqrt{2}}\\left(|0\\rangle + |1\\rangle\\right)$\n",
    "\n",
    "Thus, just as before, we construct an error function that we have to minimize. The function this time will be:\n",
    "$$f = (real(|0\\rangle) - \\frac{1}{\\sqrt{2}})^2 + (real(|1\\rangle) - \\frac{1}{\\sqrt{2}})^2$$\n",
    "\n",
    "For this, let us define a function that returns us the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value of the function:  1.724734169765496e-08\n",
      "Value of theta for minnima of function:  [1.57079819 4.59713454]\n"
     ]
    }
   ],
   "source": [
    "def function_for_H(theta, no_of_measurements):\n",
    "    circuit = QuantumCircuit(1)\n",
    "    \n",
    "    circuit.ry(theta[0],0)\n",
    "    circuit.rx(theta[1],0)\n",
    "    \n",
    "    state = execute(circuit, backend).result().get_statevector()\n",
    "    function_val = ((float(state[0].real) - (1/2)**(1/2))**2 + (float(state[1].real) - (1/2)**(1/2))**2)\n",
    "    return function_val\n",
    "\n",
    "initial_theta = [random.uniform(0,2*np.pi), random.uniform(0,2*np.pi)]\n",
    "    \n",
    "min_function_value, min_theta = gradient_descent(initial_theta, function_for_H, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00419504+0.00000000e+00j  0.70709426-1.30538304e-06j\n",
      "  0.70709441+0.00000000e+00j -0.00419504+7.74455274e-09j]\n"
     ]
    }
   ],
   "source": [
    "def checking_state(X_results, min_theta):   \n",
    "    circuit = QuantumCircuit(2)\n",
    "\n",
    "    # X gate on qubit 1\n",
    "    circuit.ry(X_results[n][1][0],1)\n",
    "\n",
    "    # H gate on qubit 0\n",
    "    circuit.ry(min_theta[0],0)\n",
    "    circuit.rx(min_theta[1],0)\n",
    "\n",
    "    # CNOT gate with qubit 0 as a control qubit and qubit 1 as the targer qubit\n",
    "    circuit.cx(0,1)\n",
    "    state_vector = get_state_vector(circuit)\n",
    "        \n",
    "    return state_vector\n",
    "        \n",
    "state_vector = checking_state(X_results, min_theta)\n",
    "print(state_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WE ARE DONE\n",
    "\n",
    "The state is exactly what we desired."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
